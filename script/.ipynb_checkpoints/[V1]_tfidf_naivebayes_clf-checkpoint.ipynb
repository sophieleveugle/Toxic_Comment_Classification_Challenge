{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification Challenge\n",
    "\n",
    "## Version 1.0\n",
    "\n",
    "Have you ever experienced or read toxic comments when navigating on Twitter or looking at a video on Youtube ? \n",
    "\n",
    ">\"Your work is bullshit\"\n",
    "\n",
    "or \n",
    "\n",
    ">\"You should kill yourself\"\n",
    "\n",
    "Discussing things you care about can be difficult. The threat of abuse and harassment online means that many people stop expressing themselves and give up on seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments.\n",
    "\n",
    "The Conversation AI team, a research initiative founded by Jigsaw and Google (both a part of Alphabet) are working on tools to help improve online conversation. One area of focus is the study of negative online behaviors, like toxic comments (i.e. comments that are rude, disrespectful or otherwise likely to make someone leave a discussion). So far they’ve built a range of publicly available models served through the Perspective API, including toxicity. But the current models still make errors, and they don’t allow users to select which types of toxicity they’re interested in finding (e.g. some platforms may be fine with profanity, but not with other types of toxic content).\n",
    "\n",
    "* In this competition, **the aim is to build a multi-headed model that’s capable of detecting different types of  toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models**. \n",
    "\n",
    "The dataset of comments is from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.\n",
    "\n",
    "Let's get started by loading the package we are going to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this study, the english stop-words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TOC'></a>\n",
    "\n",
    "## Table of contents\n",
    "1. [Introduction](#first-bullet)  \n",
    "    1.1 [Dataset of comments](#first-bullet)  \n",
    "    1.2 [Overview of the Toxic Comments Classifier V1](#second-bullet)  \n",
    "2. [Preprocessing](#third-bullet)  \n",
    "3. [Implement the multi-label classifier](#fourth-bullet)  \n",
    "    3.1 [Training](#fourth-bullet)  \n",
    "    3.2 [Predictions on the test set](#fifth-bullet)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Introduction <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "\n",
    "### 1.1 - Dataset of comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing and exploring the dataset.\n",
    "\n",
    "The dataset (X, Y) is quite large :\n",
    "\n",
    "* X contains 159571 sentences (strings)\n",
    "* Y contains 6 independent binary labels corresponding to the type of the threat\n",
    "\n",
    "Let's load the dataset using the code below. The dataset is already split between training (159571 examples) and testing (153164 examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col=0)\n",
    "X_train = train['comment_text']\n",
    "y_train = train.drop('comment_text', axis=1)\n",
    "X_test = pd.read_csv('../data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types of the threat are the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Type of threat --\n",
      "toxic\n",
      "severe_toxic\n",
      "obscene\n",
      "threat\n",
      "insult\n",
      "identity_hate\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Type of threat --\")\n",
    "for i in range(6):\n",
    "    print(list(y_train.columns)[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell print examples of sentences from X_train corresponding to toxic labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "-------------------------------\n",
      "Hey... what is it..\n",
      "@ | talk .\n",
      "What is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\n",
      "\n",
      "Ask Sityush to clean up his behavior than issue me nonsensical warnings...\n",
      "-------------------------------\n",
      "Bye! \n",
      "\n",
      "Don't look, come or think of comming back! Tosser.\n",
      "-------------------------------\n",
      "You are gay or antisemmitian? \n",
      "\n",
      "Archangel WHite Tiger\n",
      "\n",
      "Meow! Greetingshhh!\n",
      "\n",
      "Uh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\n",
      "\n",
      "1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\n",
      "\n",
      "2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\n",
      "\n",
      "3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\n",
      "\n",
      "Beware of the Dark Side!\n",
      "-------------------------------\n",
      "FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx in np.where(y_train['toxic'])[0][:5]:\n",
    "    print(X_train[idx])\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label index 'Toxic' in one-hot encoding format is [1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 300\n",
    "print(f\"Label index 'Toxic' in one-hot encoding format is {list(y_train.iloc[idx])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specificity of our dataset is that a comment could have multiple labels. For example, a comment could be *toxic* but also *insane*.\n",
    "\n",
    "Back to [table of contents](#TOC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Overview of the Toxic Comments Classifier V1 <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "\n",
    "#### Inputs and outputs\n",
    "* The input of the model is a string corresponding to a sentence (e.g. \"Beware of the Dark Side!\"). \n",
    "* The output will be a probability vector of shape (1,6), (there are 6 possible types of comments to choose from)\n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "* Clean the comments removing or replacing useless word and contractions\n",
    "* Score the relative importance of words using TF-IDF for each comment (this part will be included in the pipeline)\n",
    "\n",
    "For each document, the number of times a word appears in it divided by the total number of words in the document is computed. Every document has its own term frequency.\n",
    "\n",
    ">Term-frequency (TF)\n",
    "$$tf_{i,j}=\\frac{n_{i,j}}{\\sum_{k} n_{i,j} }$$\n",
    "\n",
    "Then, the IDF (Inverse Data Frequency) is computed, i.e. the log of the number of documents divided by the number of documents that contain the word w. Inverse data frequency determines the weight of rare words across all documents in the corpus.\n",
    "\n",
    ">Inverse Data Frequency (IDF)\n",
    "$$idf(w)=log(\\frac{N}{df_t})$$\n",
    "\n",
    "The IDF is computed once for all documents.\n",
    "\n",
    "Lastly, the TF-IDF is simply the TF multiplied by IDF.\n",
    "\n",
    "$$w_{i,j}=tf_{i,j}*log(\\frac{N}{df_i})$$\n",
    "\n",
    "The TF-IDF scores are computed for all the words in the corpus.\n",
    "\n",
    "#### Multi-label classifier\n",
    "\n",
    "* The strategy used here consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. This method is implemented in the ```OneVsRestClassifier``` class in **sklearn**. \n",
    "* The chosen estimator for the example is the multinomial Naive Bayes classifier (```MultinomialNB```) but others could be tested and compare.\n",
    "* The classifier is evaluated using the accuracy score computed on a validation set. \n",
    "\n",
    "#### Subsmission\n",
    "\n",
    "Back to [table of contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Preprocessing <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the overview, the first step is to clean the comments removing or replacing certain expressions.\n",
    "\n",
    "Here is a comment :\n",
    "\n",
    "```\n",
    "Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169\n",
    "```\n",
    "\n",
    "Different contractions could be noticed here. For instance, \"$I'm$\" is the contraction of \"$I am$\". In this form, it could be considered as a different word, what we don't want.\n",
    "\n",
    "The first step is to implement a function that will carry this out. Here are the different steps :\n",
    "\n",
    "* Convert every sentence to lower-case\n",
    "* Remove the unwanted expressions with regular expression operations\n",
    "* Remove characters from both left and right based on the argument\n",
    "\n",
    "These steps are implemented in the ```clean_one_comment()``` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_one_comment(comment):\n",
    "    \"\"\"\n",
    "    Clean a sentence (string) by converting it into lower case, removing or replacing unwanted expressions \n",
    "    and removing characters from both left and right.\n",
    "    \n",
    "    Arguments:\n",
    "    comment -- string, one training example from X\n",
    "    \n",
    "    Returns:\n",
    "    cleaned_comment -- cleaned string\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Transform the string into lower case words\n",
    "    comment_lower = comment.lower()\n",
    "    \n",
    "    # Step 2: Remove or replace the unwanted expressions (more could be added)\n",
    "    comment_inter = re.sub(r\"i'm\", \"i am \", comment_lower)\n",
    "    comment_inter = re.sub(r\"what's\", \"what is \", comment_inter)\n",
    "    comment_inter = re.sub(r\"\\'ve\", \" have \", comment_inter)\n",
    "    comment_inter = re.sub(r\"\\'s\", \" \", comment_inter)\n",
    "    comment_inter = re.sub(r\"can't\", \"can not \", comment_inter)\n",
    "    comment_inter = re.sub(r\"n't\", \" not \", comment_inter)\n",
    "    comment_inter = re.sub(r\"\\'re\", \" are \", comment_inter)\n",
    "    comment_inter = re.sub(r\"\\'d\", \" would \", comment_inter)\n",
    "    comment_inter = re.sub(r\"\\'ll\", \" will \", comment_inter)\n",
    "    comment_inter = re.sub(r\"\\'scuse\", \" excuse \", comment_inter)\n",
    "    comment_inter = re.sub('\\W', ' ', comment_inter)\n",
    "    comment_inter = re.sub('\\s+', ' ', comment_inter)\n",
    "    # ...\n",
    "    \n",
    "    # Step 3: Remove characters from both left and right \n",
    "    cleaned_comment = comment_inter.strip()\n",
    "    \n",
    "    return cleaned_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean comment = \n",
      " sorry if the word nonsense was offensive to you anyway i am not intending to write anything in the article wow they would jump on me for vandalism i am merely requesting that it be more encyclopedic so one can use it for school as a reference i have been to the selective breeding page but it almost a stub it points to animal breeding which is a short messy article that gives you no info there must be someone around with expertise in eugenics 93 161 107 169\n"
     ]
    }
   ],
   "source": [
    "clean_comment = clean_one_comment(X_train[8])\n",
    "print(\"Clean comment = \\n\", clean_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "```\n",
    "Clean comment = \n",
    " sorry if the word nonsense was offensive to you anyway i am not intending to write anything in the article wow they would jump on me for vandalism i am merely requesting that it be more encyclopedic so one can use it for school as a reference i have been to the selective breeding page but it almost a stub it points to animal breeding which is a short messy article that gives you no info there must be someone around with expertise in eugenics 93 161 107 169\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this function on all the comments column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lambda x: clean_one_comment(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [table of contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Implement the multi-label classifier <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "\n",
    "### 3.1 - Training\n",
    "\n",
    "Let's now implement the ```multi_head_model()``` function. The steps of this function are the following :\n",
    "1. Extract the different Y labels into a list.\n",
    "2. Define the pipeline.\n",
    "    * Using the ```TfidfVectorizer``` function and the ```OneVsRestClassifier``` function.\n",
    "    * The model used here for the example is a Naive Bayes classifier.\n",
    "3. For each label, fit the pipeline to the training set and test it on the validation set.\n",
    "4. Store the result in a table using ```PrettyTable```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_model(X, y):\n",
    "    \"\"\"\n",
    "    Model to train a multi-label classifier.\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
    "    Y -- labels, binary numpy arrays of shape (m, p)\n",
    "\n",
    "    Returns:\n",
    "    pred -- vector of predictions, numpy-array of shape (m, p)\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Extract the different Y labels into a list\n",
    "    labels = list(y.columns)\n",
    "\n",
    "    # Step 2: Define the pipeline (with TfidfVectorizer and one classifier with OneVsRestClassifier)\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "        ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "            fit_prior=True, class_prior=None))),\n",
    "    ])\n",
    "\n",
    "    # Initialize the dictionary to store each trained classifier\n",
    "    trained_classifier = dict()\n",
    "    \n",
    "    # Initialize the list to store the accuracy\n",
    "    auc_classifier = list()\n",
    "\n",
    "    # Step 3: For each label, fit the pipeline to the training set and test it on the validation set\n",
    "    for label in labels:\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y[label], random_state=42, test_size=0.2, shuffle=True)\n",
    "        print('... Training for label: {}'.format(label))\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        prediction = pipeline.predict(X_valid)\n",
    "        print('Validation AUC is {}'.format(roc_auc_score(y_valid, prediction)))\n",
    "        trained_classifier.update({label: pipeline})\n",
    "        auc_classifier.append(roc_auc_score(y_valid, prediction))\n",
    "        \n",
    "    # Step 4: Store the result in a table\n",
    "    result_table = PrettyTable()\n",
    "    column_names = [\"Threat\", \"AUC\"]\n",
    "    result_table.add_column(column_names[0], labels)\n",
    "    result_table.add_column(column_names[1], acc_classifier) \n",
    "\n",
    "    return trained_classifier, result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training for label: toxic\n",
      "Validation accuracy is 0.5892631582623512\n",
      "... Training for label: severe_toxic\n",
      "Validation accuracy is 0.4999841742102931\n",
      "... Training for label: obscene\n",
      "Validation accuracy is 0.5568016430791806\n",
      "... Training for label: threat\n",
      "Validation accuracy is 0.5067567567567568\n",
      "... Training for label: insult\n",
      "Validation accuracy is 0.5250434334862517\n",
      "... Training for label: identity_hate\n",
      "Validation accuracy is 0.4999841877233484\n"
     ]
    }
   ],
   "source": [
    "trained_classifier, result_table = multi_head_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result_table.get_html_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Threat</th>\n",
    "        <th>AUC</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>toxic</td>\n",
    "        <td>0.5892631582623512</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>severe_toxic</td>\n",
    "        <td>0.4999841742102931</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>obscene</td>\n",
    "        <td>0.5568016430791806</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>threat</td>\n",
    "        <td>0.5067567567567568</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>insult</td>\n",
    "        <td>0.5250434334862517</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>identity_hate</td>\n",
    "        <td>0.4999841877233484</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to [table of contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Predictions on the test set <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "\n",
    "Let's now implement the function ```predict_multi_head``` to predict the labels of the comments in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multi_head(X_test, set_of_classifiers):\n",
    "    \"\"\"\n",
    "    Predict a threat for the comments in the test set.\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
    "    Y -- labels, binary numpy arrays of shape (m, p)\n",
    "\n",
    "    Returns:\n",
    "    predictions -- vector of predictions, numpy-array of shape (m, p)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Get the labels for the dictionary keys (set_of_classifiers)\n",
    "    labels = list(set_of_classifiers.keys())\n",
    "    \n",
    "    # Initialize the array to append\n",
    "    predictions = np.empty((0, len(X_test.comment_text)))\n",
    "    \n",
    "    # Step 2: For each label, predict the labels\n",
    "    for label in labels:\n",
    "        pred = set_of_classifiers[label].predict_proba(X_test.comment_text)[:,1]\n",
    "        predictions = np.append(predictions, [pred], axis=0)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_multi_head(X_test, trained_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the result into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(predictions.T, columns=y_train.columns, index=X_test.index).reset_index()\n",
    "submission.to_csv(path_or_buf=\"../submissions/submission_file.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Final score</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>-</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "So, this is clearly not the best methodology as people on the leaderboard achieve much higher scores (~0.98). \n",
    "\n",
    ">Let's try other classical machine learning and deep learning algorithms.\n",
    "\n",
    "Back to [table of contents](#TOC)\n",
    "\n",
    "**Note**\n",
    "\n",
    "* Cleaning the comments doesn't change anything to the validation accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
